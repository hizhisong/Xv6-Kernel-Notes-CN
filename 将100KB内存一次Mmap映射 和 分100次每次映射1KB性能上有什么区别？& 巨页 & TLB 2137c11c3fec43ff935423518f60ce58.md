# 将100KB内存一次Mmap映射 和 分100次每次映射1KB性能上有什么区别？& 巨页 & TLB

板块: 内存管理

## TLB？

利用 TLB 加速地址翻译

![Untitled](%E5%B0%86100KB%E5%86%85%E5%AD%98%E4%B8%80%E6%AC%A1Mmap%E6%98%A0%E5%B0%84%20%E5%92%8C%20%E5%88%86100%E6%AC%A1%E6%AF%8F%E6%AC%A1%E6%98%A0%E5%B0%841KB%E6%80%A7%E8%83%BD%E4%B8%8A%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F&%20%E5%B7%A8%E9%A1%B5%20&%20TLB%202137c11c3fec43ff935423518f60ce58/Untitled.png)

[TLB原理](https://zhuanlan.zhihu.com/p/108425561)

TLB和CPU Cache一样，就是一个专用的缓存

TLB的 虚拟地址 和 Cacheline 映射可以是采用 直接映射、全相连映射或组相连映射

这里为[全相连映射](CacheLine%E7%9A%84%E6%98%A0%E5%B0%84%201e6b54b74dc04ea995ed4453b1bfbf79.md)的TLB Cache为例，我们展示下一个虚拟地址在TLB中如何找到对应指出物理地址的PTE

![Untitled](%E5%B0%86100KB%E5%86%85%E5%AD%98%E4%B8%80%E6%AC%A1Mmap%E6%98%A0%E5%B0%84%20%E5%92%8C%20%E5%88%86100%E6%AC%A1%E6%AF%8F%E6%AC%A1%E6%98%A0%E5%B0%841KB%E6%80%A7%E8%83%BD%E4%B8%8A%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F&%20%E5%B7%A8%E9%A1%B5%20&%20TLB%202137c11c3fec43ff935423518f60ce58/Untitled%201.png)

## 将100KB内存一次Mmap映射 和 分100次每次映射1KB性能上有什么区别？

1. 一次映射100KB这100KB是连续虚拟地址空间，物理内存上一个页上也是连续的，分100次映射可能会导致每次1KB的内存申请出一个物理页导致产生较多内存碎片，地址空间上也可能都不连续
2. 由于内存分配最小的单位是一页，因此无论是通过MMU还是TLB找到虚拟地址对应的物理地址，我们只需要提供虚拟地址空间所在页的其实地址(虚拟地址的页号部分)就可以翻译成对应物理页的起始物理地址；再利用虚拟地址中的页内偏移部分定位在物理页的偏移从而找到虚拟地址对应的物理地址
    
    也就是说，一个页内的所有虚拟地址都对应一个页号，那么在TLB中又是以 一个页起始地址 -- 一个页起始物理地址 这样的kv们存储，那么这个页中所有虚拟地址查TLB时都能击中缓存，返回物理页起始地址
    
    多次mmap会造成每次mmap都可能是重新alloc一个新的物理页，那么TLB缓存有限，对这100KB访问势必会出现缓存missing，需要MMU重新翻译并在TLB中缓存，而一次性mmap占用的物理页数更少些，在TLB中就更容易被击中(hit)
    

## 大量分配连续内存 且 需要减少TLB missing -- 巨页

有一个场景是：

我们常常一次性需要分配大量内存，这些内存在用户虚拟地址空间是连续的，我们在分配物理内存时，allocator是按照一页一页分配的，MMU和TLB也是按照地址所在页而翻译的，如果由于页小分配页过多，TLB缓存不下这么多虚拟页—物理页的映射关系，因此我们每次访问虚拟地址空间时在TLB中找不到虚拟地址所属的虚拟页的映射关系缓存时就去MMU重新翻译

为了减少MMU翻译次数，增加TLB缓存击中，我们可以对内存分页时将每个页的大小从2KB、4KB这样的值增大，代价是一个页表页中PTE数增加，页表本身存储增大