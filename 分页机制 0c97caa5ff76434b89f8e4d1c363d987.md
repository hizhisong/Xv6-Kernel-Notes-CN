# 分页机制

Status: Completed
板块: 内存管理

# 地址转化

用户进程虚拟地址空间 --> 内核虚拟地址空间: 

在内核态中：内核模拟MMU遍历用户页表

在用户态中：硬件MMU+TLB

内核虚拟地址空间 --> 物理地址空间: 硬件MMU+TLB

# 页表、页表项、页表页、目标页

页表让操作系统控制虚拟地址到物理地址的转换，基于Sv39 RISC-V的Xv6采用了三级页表的方法：

- 第一级页表(根页表)仅有一个4KB的页表页，内含(4*1024/(64/8) = 512)个页表项(PTE)
    - **页表项(PTE)**: 占用64位，实际使用低54位，存的是 下一级页表的某一页/目标页 的起始物理地址，一个页表项代表的就是**一个页**的寻址了
    - 一个**页表页**有512个页表项(4KB*1024bytes/(64bits/8bits)bytes = 512)
- 第二级至少有一个页表页，由上级页表项(PTE)指向，这级某一页的某个页表项指向下一级页表的某一页物理地址
- 第三级至少有一个页表页，由上级页表项(PTE)指向，这级某一页的某个页表项指向目标页物理地址

<aside>
💡 我们清醒一点：
页表(Page table)其中的这几级页表页都是实实在在占用着物理内存
他们本身就是由 页(Pages) 组成，有页地址起始物理地址，某个页表项也是单独某页其中的8字节，页表项本身也有地址，页表项存储着下级页表**页**的起始地址，具体下级页表的页中哪一项由虚拟地址的9位定

</aside>

# 虚拟地址 --> 物理地址

分页硬件通过利用**虚拟地址**底部39位中的高27位索引到页表中找到一个PTE页表项来转换一个虚拟地址，计算出一个56位的物理地址，它的前44位来自于PTE中的PPN，而它的后12位则是从原来的虚拟地址复制过来的。

![图片1.png](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/%E5%9B%BE%E7%89%871.png)

我们基于找到的目标物理页结合上虚拟地址的低12位在物理页上做offset计算找到我们的目标物理地址

## 细化寻找目标页

我们采用的是三级页表：

- 虚拟地址的高九位L2: 选择根页表页中的**PTE**，该PTE指向下级页表中的某一页(PTE的值由下级页表页的页号(起始地址)和标记位组成，我们可以左移清除标记位，再右移腾出一个页寻址大小(4096bytes/page -- 12bits addr)，用于使用va的一部分对下级页表页进行PTE定位)
- 虚拟地址的中九位L1: 根据上级页表页PTE选出的物理页起始地址，以及L1提供的值在该页上定位到PTE，该PTE指向下级页表中的某一页
- 虚拟地址的低九位L0: 根据上级页表页PTE选出的物理页起始地址，以及L0提供的值在该页上定位到PTE，该PTE指向**目标物理页**

>>> 我们再通过找到的 物理页PPN 与所找位置在物理页中的 偏移量 **合成**一个**物理地址**

![图片2.png](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/%E5%9B%BE%E7%89%872.png)

![注意：PTE的PPN指的是物理页号 也就是某一物理页开始的地址](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/%E5%9B%BE%E7%89%873.png)

注意：PTE的PPN指的是物理页号 也就是某一物理页开始的地址

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled.png)

```cpp
// Return 'the address of the PTE' in page table pagetable
// that **corresponds to** virtual address 'va'.  If alloc!=0,
// create any required page-table pages.
//
// The risc-v Sv39 scheme has three levels of page-table
// pages. A page-table page contains 512 64-bit PTEs.
// A 64-bit virtual address is split into five fields:
//   39..63 -- must be zero.
//   30..38 -- 9 bits of level-2 index.
//   21..29 -- 9 bits of level-1 index.
//   12..20 -- 9 bits of level-0 index.
//    0..11 -- 12 bits of byte offset within the page.

// 通过虚拟地址得到最低层PTE的指针，这个PTE内容包含物理地址所在页页首地址（因此一定能被%PAGESIZE整除）

// 模仿RISC-V分页硬件查找虚拟地址的PTE。walk每次降低3级页表的9位。
// 它使用每一级的9位虚拟地址来查找下一级页表或最后一级（kernel/vm.c:78）的PTE。
// **为什么要采用9位虚拟地址索引一个页表页的PTE呢？**
//  2^9 = 512，一个页表页4K，一个页表项64位(8bytes)，那么一个页表页有512个页表项，正好可以使用512个地址给每个PTE索引

// 功能：返回包含虚拟地址对应物理地址所在物理页起始地址信息的PTE的地址
// 若alloc为1，那么当我们试图找一个不存在映射关系的虚拟地址时：
// 在根页表找不到对应合法PTE，那么就Alloc一页作为下级页表页，并建立本级PTE对新建页的PTE关联
// 下级页表页上操作类似，也是Alloc一页作为下级页表页，并建立本级PTE对新建页的PTE关联
// 最终返回最后一级页表页上包含虚拟地址对应物理地址所在物理页信息的PTE地址，而不会对不存在目标物理页生成(注意walk中for终止条件为>0不是>=0)
pte_t *
walk(pagetable_t pagetable, uint64 va, int alloc)
{
  if(va >= MAXVA)
    panic("walk");

  for(int level = 2; level > 0; level--) {
    pte_t *pte = &pagetable[PX(level, va)];     // 获取虚拟地址的某'层'的九位PTE索引 在这层页表的页表页中定位到PTE的地址
                                                // PTE作为一个64位变量在页表页中自身有地址同时存着物理页地址
    if(*pte & PTE_V) {    // PTE存的地址是指向下级页表的某页
      pagetable = (pagetable_t)PTE2PA(*pte);
    } else {              // PTE指向不存在页，即va定位的下级页表不存在
      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)     // pagetable被更新为下级新生成的物理页地址
        return 0;
      memset(pagetable, 0, PGSIZE);
      *pte = PA2PTE(pagetable) | PTE_V;       // 为下级页表新建一页，将该页起始物理地址变化填充到本级PTE中
    }
  }
  return &pagetable[PX(0, va)];               // 返回va对应的 指向其物理页起始物理地址 的PTE的地址
}
```

```c
#define PGSIZE 4096 // bytes per page 一个内存页的大小
#define PGSHIFT 12  // bits of offset within a page 一个内存页的页内偏移 用于物理地址低12位(2^12 = 4096)

#define PGROUNDUP(sz)  (((sz)+PGSIZE-1) & ~(PGSIZE-1))  // 取整
#define PGROUNDDOWN(a) (((a)) & ~(PGSIZE-1))

#define PTE_V (1L << 0) // valid      // PTE低10位作为flag位
#define PTE_R (1L << 1)
#define PTE_W (1L << 2)
#define PTE_X (1L << 3)
#define PTE_U (1L << 4) // 1 -> user can access

// shift a physical address to the right place for a PTE.
#define PA2PTE(pa) ((((uint64)pa) >> 12) << 10)     // 某个物理页中所有地址的12~55位都是一样的 0~11位不一样 是各自在页中的offset
                                                    // 对某物理地址右移12位再左移10位形成的是 代表原本页的 PTE, PTE第10位为它的flags位

#define PTE2PA(pte) (((pte) >> 10) << 12)           // 删除PTE的flags位，恢复成该PTE所代表 原本物理页的起始物理地址
                                                    // 低12位为页中offset,全为0则说明是某页起点

#define PTE_FLAGS(pte) ((pte) & 0x3FF)              // 0x3FF = 11 1111 1111
                                                    // 获取PTE中被标记的flags

// extract the three 9-bit page table indices from a virtual address.
// 虚拟地址中三级页表对应每级页表页的页号都是9位, 第12位为页内偏移offset，与物理地址第12位一致
#define PXMASK          0x1FF                       // 9 bits   0x1FF = 1 1111 1111
#define PXSHIFT(level)  (PGSHIFT+(9*(level)))
#define PX(level, va) ((((uint64) (va)) >> PXSHIFT(level)) & PXMASK)  // 从虚拟地址中获取第level级页表页中某个PTE的索引(页内偏移量) 

// one beyond the highest possible virtual address.
// MAXVA is actually one bit less than the max allowed by
// Sv39, to avoid having to sign-extend virtual addresses
// that have the high bit set.
#define MAXVA (1L << (9 + 9 + 9 + 12 - 1))
```

<aside>
💡

学生提问：当发生page fault时，我们其实是在向一个只读的地址执行写操作。内核如何能分辨现在是一个copy-on-write fork的场景，而不是应用程序在向一个正常的只读地址写数据。是不是说默认情况下，用户程序的PTE都是可读写的，除非在copy-on-write fork的场景下才可能出现只读的PTE？
Frans教授：内核必须要能够识别这是一个copy-on-write场景。几乎所有的page table硬件都支持了这一点。我们之前并没有提到相关的内容，下图是一个常见的多级page table。对于PTE的标志位，我之前介绍过第0bit到第7bit，但是没有介绍**最后两位RSW**。这两位保留给supervisor software使用，supervisor softeware指的就是内核。内核可以随意使用这两个bit位。所以可以做的一件事情就是，将bit8标识为当前是一个copy-on-write page。

</aside>

<aside>
💡 1. PTEs contain the **physical addresses** for page-table pages in the **next level** of the tree.
2. 如果转换一个地址所需的三个PTE中的任何一个不存在，分页硬件就会引发一个页面错误的异常/分页异常(page-fault exception)，让内核来处理这个异常(CPU运行内核中提前设置好的分页异常处理函数handler)
3. 这种三层结构的一种好处是，当有大范围的虚拟地址没有被映射时，可以**省略整个页表页。**

</aside>

<aside>
💡 **至此，我们务必记清楚虚拟地址、物理地址、PTE的每一位组成
页表、页表页、多级页表、物理页间的关系**

</aside>

## satp寄存器 -- 如何处理每个CPU上进程的虚拟地址空间

为了让硬件使用页表，内核必须将根页表页的物理地址写入satp寄存器(根页表寄存器)中。每个CPU都有自己的satp寄存器。一个CPU将使用自己的satp所指向的页表来翻译后续指令产生的所有地址。每个CPU都有自己的satp，这样不同的CPU可以运行不同的进程，每个进程都有自己的页表所描述的私有地址空间。

<aside>
💡 对于内核虚拟地址空间 --> 物理地址空间 方法就是由MMU执行上述过程，辅助以TLB作为页表项缓存，MMU、TLB均集成在CPU内部
对于用户进程虚拟地址空间 --> 内核虚拟地址空间，Xv6中主要由`vm.c`对此进行了软件上的模拟模型，以达到给用户虚拟地址空间分配内核虚拟地址空间的目标

</aside>

# 模拟MMU -- 代码实现

## 核心数据结构与宏

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%201.png)

注意这里，核心数据结构就是`pte_t`, `pagetable_t`

`pte_t`表示页表项的值，其占用64位空间

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%202.png)

`pagetable_t` 可以是内核页表中的某层某页，也可以是进程的页表，占用64位，是页表这一组页的起始**物理地址**

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%203.png)

<aside>
💡 我们映射是的基本操作单位也是页：
一个PTE值表示某个页的起始物理地址+flags
页表中每级有若干页表页，每个页就是内存页4K，可存512个PTEs

</aside>

## 【walk】返回va对应的 指向 其对应物理地址所在物理页起始物理地址 的PTE的地址(最后一级页表页中某页的某个PTE地址)

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%204.png)

<aside>
💡 当alloc=1时，当我们试图找一个不存在映射关系的虚拟地址时，会发生什么？
—

若alloc为1，那么当我们试图找一个不存在映射关系的虚拟地址时：

在根页表找不到对应合法PTE，那么就Alloc一页作为下级页表页，并建立本级PTE对新建页的PTE关联

下级页表页上操作类似，也是Alloc一页作为下级页表页，并建立本级PTE对新建页的PTE关联

最终返回最后一级页表页上包含虚拟地址对应物理地址所在物理页信息的PTE地址，而不会对不存在目标物理页生成(注意walk中for终止条件为**>**0不是**>=**0)

</aside>

## 【walkaddr】根据虚拟地址返回 物理地址所在 物理页 的起始地址

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%205.png)

## 【mappages】建立虚拟地址与物理地址间的映射

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%206.png)

## 【uvmunmap】用户页表取消虚拟地址与物理地址间的映射

标记清除法将代表物理页的PTE值填充为0

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%207.png)

# 用户虚拟地址空间的页表使用

## 【uvmcreate】新建一个用户页表

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%208.png)

## 【uvmalloc】用户虚拟地址空间动态内存分配(扩容)

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%209.png)

## 【uvmdealloc】free用户地址空间中动态分配的空间

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%2010.png)

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%2011.png)

用户使用sbrk系统调用扩展heap时是lazy allocation，仅仅增加p->sz大小，等真正使用时遇到page fault再去申请内存、建立页表项的映射

![Untitled](%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%200c97caa5ff76434b89f8e4d1c363d987/Untitled%2012.png)

// 栈(用户栈、内核栈) 堆

内核用brk/sbrk进一批货，malloc来零售